{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, isfile, isdir\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "# import pathlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras import models\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # flag used to run tasks on more threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# tf.random.set_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# path = 'server\\\\driller'\n",
    "# categories = np.array(tf.io.gfile.listdir(path)) # loads categorized datasets folders \n",
    "# filenames = tf.io.gfile.glob(path + '/*/*') # loads all files from all dataset categories\n",
    "# filenames = tf.random.shuffle(filenames) # shuffle all files\n",
    "# num_of_samples = len(filenames) \n",
    "# print(categories)\n",
    "\n",
    "# train_files = filenames[:int((num_of_samples)*0.8)]\n",
    "# validation_files = filenames[int((num_of_samples)*0.8):int((num_of_samples)*0.8+(num_of_samples)*0.1)]\n",
    "# test_files = filenames[int(-(num_of_samples)*0.1):]\n",
    "# print(len(train_files), len(validation_files), len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "path = 'noiseanalyzer\\\\server\\\\driller\\\\'\n",
    "# categories = np.array(listdir(path)) # loads categorized datasets folders  # loads all files from all dataset categories\n",
    "categories = listdir(path)\n",
    "filenames = [join(path, category, file) for category in categories if isdir(join(path, category)) for file in listdir(join(path, category)) if isfile(join(path, category, file))]\n",
    "# filenames = (glob.glob(path + '/*/*')) \n",
    "filenames = tf.random.shuffle(filenames)\n",
    "# filenames = np.array(np.random.shuffle(filenames))\n",
    "# filenames = np.array(filenames)\n",
    "# filenames = tf.io.gfile.glob(str(data_dir) + '/*/*') # loads all files from all dataset categories\n",
    "# filenames = tf.random.shuffle(filenames) # shuffle all files\n",
    "print(categories)\n",
    "num_of_samples = len(filenames) \n",
    "# slicing dataset files to tranin, valid, test.\n",
    "train_files = filenames[:int((num_of_samples)*0.8)]\n",
    "validation_files = filenames[int((num_of_samples)*0.8):int((num_of_samples)*0.8+(num_of_samples)*0.1)]\n",
    "test_files = filenames[int(-(num_of_samples)*0.1):]\n",
    "print(f'train data: {len(train_files)}')\n",
    "print(f'validation data: {len(validation_files)}')\n",
    "print(f'test data: {len(test_files)}')\n",
    "print(f'Total: {len(train_files)+len(validation_files)+len(test_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_audio(file_path):\n",
    "#     audio_binary = tf.io.read_file(file_path)\n",
    "#     audio, _ = tf.audio.decode_wav(audio_binary, desired_samples=22050)\n",
    "#     return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "# def get_label(file_path):\n",
    "#     parts = tf.strings.split(file_path, os.path.sep)\n",
    "#     return parts[-2]\n",
    "\n",
    "# def get_wav_and_label(file_path):\n",
    "#     label = get_label(file_path)\n",
    "#     wav = decode_audio(file_path)\n",
    "#     return wav, label\n",
    "\n",
    "def load_record_with_label(path):\n",
    "    # audio_binary = tf.io.read_file(path)\n",
    "    data, _ = tf.audio.decode_wav(tf.io.read_file(path), desired_samples=22050)\n",
    "    return tf.squeeze(data, axis=-1), tf.strings.split(path, '\\\\')[-2]\n",
    "\n",
    "\n",
    "def load_spectrogram_with_label(record, label): #return spectrogram and coresponding label as idx of category\n",
    "    data = tf.cast(record, tf.float32)\n",
    "    spectrogram = tf.signal.stft(data, frame_length=1024, frame_step=512, window_fn=tf.signal.hann_window, pad_end=True)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_id = tf.argmax(label == categories)\n",
    "    return spectrogram, label_id\n",
    "\n",
    "def create_dataset(files):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(files)\n",
    "    records_ds = dataset.map(load_record_with_label, num_parallel_calls=AUTOTUNE)\n",
    "    # spectrograms_ds = records_ds.map(load_spectrogram_with_label,  num_parallel_calls=AUTOTUNE)\n",
    "    return records_ds.map(load_spectrogram_with_label,  num_parallel_calls=AUTOTUNE)\n",
    "    # return spectrograms_ds\n",
    "\n",
    "train_dataset = create_dataset(train_files)\n",
    "validation_dataset = create_dataset(validation_files)\n",
    "test_dataset = create_dataset(test_files)\n",
    "print(len(train_dataset), len(validation_dataset), len(test_dataset))\n",
    "\n",
    "for spectrogram, _ in train_dataset.take(1):\n",
    "  shape = spectrogram.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(wav):\n",
    "    wav = tf.cast(wav, tf.float32)\n",
    "    spectrogram = tf.signal.stft(\n",
    "        wav, frame_length=255, frame_step=128, window_fn=tf.signal.hann_window)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "for wav, label in train_dataset.take(1):\n",
    "  label = label.numpy().decode('utf-8')\n",
    "  spectrogram = get_spectrogram(wav)\n",
    "\n",
    "print('Label:', label)\n",
    "print('Waveform shape:', wav.shape)\n",
    "print('Spectrogram shape:', spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "    log_spec = np.log(spectrogram.T)\n",
    "    height = log_spec.shape[0]\n",
    "    X = np.arange(22050, height)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(log_spec)\n",
    "\n",
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(wav.shape[0])\n",
    "axes[0].plot(timescale, wav.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, 22050])\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 4, 4\n",
    "take = 0\n",
    "random_files = np.random.choice(filenames, int(rows*cols))\n",
    "print(random_files)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 12))\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        sample_ds = create_dataset([random_files[take]])\n",
    "        for spectrogram, label in sample_ds.batch(1):\n",
    "            filename = str(random_files[take]).split(\".\")[0].split(os.path.sep)\n",
    "            filename = join(filename[-3], filename[-1])\n",
    "            label = categories[label[0]]\n",
    "            log_spec = np.log(np.squeeze(spectrogram.numpy()).T)\n",
    "            height = log_spec.shape[0]\n",
    "        #   X = np.arange(22050, height)\n",
    "        #   Y = range(height)\n",
    "            axes[i][j].pcolormesh(log_spec)\n",
    "            axes[i][j].title.set_text(f'{label.capitalize()} ({filename})')\n",
    "            take+=1\n",
    "    \n",
    "plt.subplots_adjust(top=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "validation_dataset = validation_dataset.batch(batch_size)\n",
    "\n",
    "# Add dataset cache() and prefetch() operations to reduce read latency while training the model.\n",
    "train_dataset = train_dataset.cache().prefetch(AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_layer = preprocessing.Normalization()\n",
    "# norm_layer.adapt(train_dataset.map(lambda x, _: x))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=shape),\n",
    "    preprocessing.Resizing(32, 32), \n",
    "    # norm_layer,\n",
    "    # layers.Conv2D(filters=16, kernel_size=3, activation='relu'),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(categories)),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,  \n",
    "    epochs=10,\n",
    "    # callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=validation_dataset,  \n",
    "#     epochs=10,\n",
    "#     callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = results.history\n",
    "plt.plot(results.epoch, history['loss'], history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = []\n",
    "test_labels = []\n",
    "\n",
    "for audio, label in test_dataset:\n",
    "  test_audio.append(audio.numpy())\n",
    "  test_labels.append(label.numpy())\n",
    "\n",
    "test_audio = np.array(test_audio)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(test_audio), axis=1)\n",
    "true_labels = test_labels\n",
    "    \n",
    "accuracy = sum(predictions == true_labels) / len(true_labels)\n",
    "print(f'Test set accuracy: {accuracy:.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(test_labels, predictions) \n",
    "plt.figure(figsize=(10, 8))\n",
    "# plt.matshow(confusion_mtx)\n",
    "sns.heatmap(data=confusion_mtx, xticklabels=categories, yticklabels=categories, \n",
    "            annot=True)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_file = data_dir'/level3/audio_44.wav'\n",
    "rows, cols = 4, 4\n",
    "take = 0\n",
    "random_files = np.random.choice(filenames, int(rows*cols))\n",
    "print(random_files)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 12))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        sample_ds = create_dataset([random_files[take]])\n",
    "        for spectrogram, label in sample_ds.batch(1):\n",
    "            prediction = model(spectrogram)\n",
    "            label = categories[label[0]]\n",
    "            axes[i][j].bar(categories, tf.nn.softmax(prediction[0]))\n",
    "            filename = str(random_files[take]).split(\".\")[0].split(os.path.sep)\n",
    "            filename = join(filename[-3], filename[-1])\n",
    "            axes[i][j].title.set_text(f'{label.capitalize()} ({filename})')\n",
    "            take+=1\n",
    "plt.subplots_adjust(top=1.2)\n",
    "plt.show()\n",
    "\n",
    "# sample_file = 'server\\\\driller\\\\level_5\\\\audio_168.wav'\n",
    "\n",
    "# sample_ds = preprocess_dataset([str(sample_file)])\n",
    "\n",
    "# for spectrogram, label in sample_ds.batch(1):\n",
    "#   prediction = model(spectrogram)\n",
    "#   print(label[0])\n",
    "#   print(prediction[0])\n",
    "#   plt.bar(categories, tf.nn.softmax(prediction[0]))\n",
    "#   plt.title(f'Predictions for \"{categories[label[0]]}\"')\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nn_models/driller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}